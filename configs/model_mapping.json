{
  "model_mapping": {
    "business": {
      "primary_model": "microsoft/Phi-3.5-mini-instruct",
      "model_path": "models/microsoft_Phi-3.5-mini-instruct",
      "fallback_model": "microsoft_phi-2",
      "fallback_path": "models/microsoft_phi-2",
      "backup_model": "microsoft_DialoGPT-large",
      "backup_path": "models/microsoft_DialoGPT-large",
      "model_type": "instruction_tuned",
      "parameters": "3.8B",
      "context_length": 128000,
      "description": "Latest Phi-3.5 optimized for business conversations and professional interactions",
      "capabilities": ["reasoning", "code_generation", "business_analysis", "professional_communication"],
      "status": "preferred"
    },
    "education": {
      "primary_model": "Qwen/Qwen2.5-7B-Instruct",
      "model_path": "models/Qwen_Qwen2.5-7B-Instruct",
      "fallback_model": "microsoft_DialoGPT-large",
      "fallback_path": "models/microsoft_DialoGPT-large",
      "backup_model": "microsoft_phi-2",
      "backup_path": "models/microsoft_phi-2",
      "model_type": "instruction_tuned",
      "parameters": "7B",
      "context_length": 32768,
      "description": "Qwen2.5 optimized for educational content, tutoring, and learning assistance",
      "capabilities": ["educational_content", "tutoring", "explanation", "multilingual"],
      "status": "preferred"
    },
    "healthcare": {
      "primary_model": "meta-llama/Llama-3.2-7B-Instruct",
      "model_path": "models/healthcare/Llama-3.2-7B-Instruct",
      "fallback_model": "microsoft_phi-2",
      "fallback_path": "models/microsoft_phi-2",
      "backup_model": "microsoft_DialoGPT-large",
      "backup_path": "models/microsoft_DialoGPT-large",
      "model_type": "instruction_tuned",
      "parameters": "7B",
      "context_length": 128000,
      "description": "Llama 3.2 fine-tuned for healthcare conversations with medical knowledge",
      "capabilities": ["medical_knowledge", "healthcare_guidance", "empathetic_responses", "safety_focused"],
      "status": "target",
      "requires_token": true,
      "note": "Requires HuggingFace token and license acceptance"
    },
    "creative": {
      "primary_model": "meta-llama/Llama-3.2-7B-Instruct",
      "model_path": "models/creative/Llama-3.2-7B-Instruct",
      "fallback_model": "microsoft_DialoGPT-large",
      "fallback_path": "models/microsoft_DialoGPT-large",
      "backup_model": "microsoft_phi-2",
      "backup_path": "models/microsoft_phi-2",
      "model_type": "instruction_tuned",
      "parameters": "7B",
      "context_length": 128000,
      "description": "Llama 3.2 optimized for creative writing, storytelling, and artistic tasks",
      "capabilities": ["creative_writing", "storytelling", "brainstorming", "artistic_guidance"],
      "status": "target",
      "requires_token": true,
      "note": "Requires HuggingFace token and license acceptance"
    },
    "leadership": {
      "primary_model": "meta-llama/Llama-3.2-7B-Instruct",
      "model_path": "models/leadership/Llama-3.2-7B-Instruct",
      "fallback_model": "microsoft_DialoGPT-large",
      "fallback_path": "models/microsoft_DialoGPT-large",
      "backup_model": "microsoft_phi-2",
      "backup_path": "models/microsoft_phi-2",
      "model_type": "instruction_tuned",
      "parameters": "7B",
      "context_length": 128000,
      "description": "Llama 3.2 specialized for leadership coaching, management advice, and strategic thinking",
      "capabilities": ["leadership_coaching", "strategic_thinking", "team_management", "decision_support"],
      "status": "target",
      "requires_token": true,
      "note": "Requires HuggingFace token and license acceptance"
    },
    "universal": {
      "primary_model": "meta-llama/Llama-3.2-14B-Instruct",
      "model_path": "models/universal/Llama-3.2-14B-Instruct",
      "fallback_model": "Qwen/Qwen2.5-7B-Instruct",
      "fallback_path": "models/Qwen_Qwen2.5-7B-Instruct",
      "backup_model": "microsoft_phi-2",
      "backup_path": "models/microsoft_phi-2",
      "model_type": "instruction_tuned",
      "parameters": "14B",
      "context_length": 128000,
      "description": "Flagship universal model for all-purpose conversations and complex reasoning",
      "capabilities": ["general_conversation", "complex_reasoning", "multi_domain", "advanced_analysis"],
      "status": "flagship",
      "requires_token": true,
      "note": "Premium model - requires HuggingFace token and significant compute resources"
    }
  },
  "available_models": {
    "microsoft_DialoGPT-large": {
      "path": "models/microsoft_DialoGPT-large",
      "parameters": "762M",
      "type": "conversational",
      "license": "MIT",
      "status": "ready",
      "context_length": 1024,
      "capabilities": ["conversation", "dialogue_generation"],
      "last_verified": "2025-01-14"
    },
    "microsoft_DialoGPT-medium": {
      "path": "models/microsoft_DialoGPT-medium",
      "parameters": "345M",
      "type": "conversational",
      "license": "MIT",
      "status": "ready",
      "context_length": 1024,
      "capabilities": ["conversation", "dialogue_generation"],
      "last_verified": "2025-01-14"
    },
    "microsoft_phi-2": {
      "path": "models/microsoft_phi-2",
      "parameters": "2.7B",
      "type": "general",
      "license": "MIT",
      "status": "ready",
      "context_length": 2048,
      "capabilities": ["reasoning", "code_generation", "general_qa"],
      "last_verified": "2025-01-14"
    },
    "microsoft/Phi-3.5-mini-instruct": {
      "path": "models/microsoft_Phi-3.5-mini-instruct",
      "parameters": "3.8B",
      "type": "instruction_tuned",
      "license": "MIT",
      "status": "incomplete_download",
      "context_length": 128000,
      "capabilities": ["reasoning", "code_generation", "instruction_following", "business_analysis"],
      "last_verified": "2025-01-14",
      "note": "Missing model weight files - needs re-download"
    },
    "Qwen/Qwen2.5-7B-Instruct": {
      "path": "models/Qwen_Qwen2.5-7B-Instruct",
      "parameters": "7B",
      "type": "instruction_tuned",
      "license": "Apache 2.0",
      "status": "incomplete_download",
      "context_length": 32768,
      "capabilities": ["multilingual", "reasoning", "instruction_following", "educational_content"],
      "last_verified": "2025-01-14",
      "note": "Missing model weight files - needs re-download"
    }
  },
  "target_models": {
    "meta-llama/Llama-3.2-7B-Instruct": {
      "target_domains": ["healthcare", "creative", "leadership"],
      "parameters": "7B",
      "type": "instruction_tuned",
      "license": "Llama 3.2 Community License",
      "status": "pending_download",
      "context_length": 128000,
      "capabilities": ["advanced_reasoning", "domain_expertise", "safety_focused", "instruction_following"],
      "requires_token": true,
      "priority": "high",
      "note": "Latest Llama 3.2 - superior performance for specialized domains"
    },
    "meta-llama/Llama-3.2-14B-Instruct": {
      "target_domains": ["universal"],
      "parameters": "14B",
      "type": "instruction_tuned",
      "license": "Llama 3.2 Community License",
      "status": "pending_download",
      "context_length": 128000,
      "capabilities": ["advanced_reasoning", "complex_analysis", "multi_domain_expertise", "flagship_performance"],
      "requires_token": true,
      "priority": "flagship",
      "note": "Flagship model - best overall performance but requires significant compute"
    },
    "microsoft/Phi-3.5-mini-instruct": {
      "target_domains": ["business"],
      "parameters": "3.8B",
      "type": "instruction_tuned",
      "license": "MIT",
      "status": "needs_redownload",
      "context_length": 128000,
      "capabilities": ["business_reasoning", "code_generation", "professional_communication", "efficiency"],
      "requires_token": false,
      "priority": "high",
      "note": "Excellent for business use - needs complete re-download"
    },
    "Qwen/Qwen2.5-7B-Instruct": {
      "target_domains": ["education"],
      "parameters": "7B",
      "type": "instruction_tuned",
      "license": "Apache 2.0",
      "status": "needs_redownload",
      "context_length": 32768,
      "capabilities": ["educational_content", "multilingual", "tutoring", "explanation"],
      "requires_token": false,
      "priority": "high",
      "note": "Excellent for education - needs complete re-download"
    }
  },
  "configuration": {
    "version": "2.0",
    "default_fallback_model": "microsoft_DialoGPT-large",
    "model_loading_timeout": 300,
    "enable_model_caching": true,
    "auto_fallback_on_error": true,
    "fallback_hierarchy": ["primary_model", "fallback_model", "backup_model"],
    "model_selection_strategy": "capability_based",
    "context_window_optimization": true,
    "memory_management": {
      "enable_model_offloading": true,
      "max_concurrent_models": 2,
      "memory_threshold_gb": 16
    },
    "performance_monitoring": {
      "enable_metrics": true,
      "log_model_performance": true,
      "track_fallback_usage": true
    },
    "sync_settings": {
      "tara_ai_companion_compatible": true,
      "api_version": "v1",
      "model_endpoint_format": "huggingface",
      "supports_streaming": true
    },
    "last_updated": "2025-01-14",
    "schema_version": "2.0"
  },
  "model_status_legend": {
    "ready": "Model is downloaded and verified working",
    "incomplete_download": "Model partially downloaded, missing weight files",
    "pending_download": "Model not yet downloaded but planned",
    "needs_redownload": "Model needs to be completely re-downloaded",
    "preferred": "Recommended model for this domain",
    "target": "Target model once properly downloaded",
    "flagship": "Best overall model but requires significant resources"
  }
} 