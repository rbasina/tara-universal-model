# TARA Universal Model Dependencies

# Core ML Libraries
torch>=2.0.0
transformers>=4.30.0
peft>=0.4.0
bitsandbytes>=0.41.0
accelerate>=0.20.0
datasets>=2.12.0
evaluate>=0.4.0

# Training & Optimization
# deepspeed>=0.9.0  # Optional: Requires CUDA, skip for CPU-only training
# wandb>=0.15.0     # Optional: For experiment tracking
# tensorboard>=2.13.0  # Optional: For training visualization

# Data Processing
pandas>=2.0.0
numpy>=1.24.0
scikit-learn>=1.3.0

# Emotion Detection (Optional)
# torchaudio>=2.0.0
# librosa>=0.10.0
# speechrecognition>=3.10.0

# Web Framework
fastapi>=0.100.0
uvicorn[standard]>=0.22.0
pydantic>=2.0.0
starlette>=0.27.0

# Configuration & Utilities
pyyaml>=6.0
python-dotenv>=1.0.0
click>=8.1.0
rich>=13.4.0
tqdm>=4.65.0

# Security & Privacy
cryptography>=41.0.0
# hashlib-compat>=1.0.0  # May not be needed

# Development & Testing
pytest>=7.4.0
pytest-asyncio>=0.21.0
black>=23.0.0
flake8>=6.0.0
mypy>=1.4.0

# Jupyter & Analysis
jupyter>=1.0.0
matplotlib>=3.7.0
seaborn>=0.12.0
plotly>=5.15.0

# Optional GPU Support
# Uncomment if using specific GPU libraries
# nvidia-ml-py>=11.515.0
# cupy-cuda11x>=12.0.0

# Production Deployment
gunicorn>=21.0.0
redis>=4.6.0
celery>=5.3.0

# Cost Optimization
gpustat>=1.1.0
psutil>=5.9.0

# Optional: GGUF Support
# llama-cpp-python>=0.2.0

# Voice/TTS Support
edge-tts>=6.1.0
pyttsx3>=2.90 